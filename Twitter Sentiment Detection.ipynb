{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Diabetes prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "# Import Keras models and layers along with numpy.\n",
    "# According to keras documentation- The sequential API allows us to create models layer-by-layer, \n",
    "# so we are importing Sequentials from keras.model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# If random seed is not reseted then every time we calls different random numbers it'll generate different numbers\n",
    "# which gives us different output as every invocation.\n",
    "np.random.seed(7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 1 : LOAD DATA\n",
    "# We are loading and dividing dataset here...\n",
    "# Loading dataset in numpy array format and defining delimiter as ',' because dataset is csv file. \n",
    "dataset = np.loadtxt(\"pima-indians-diabetes-1.csv\",delimiter =\",\")\n",
    "\n",
    "#spliting dataset into X (features array) and Y(label array)\n",
    "#there are 8 features column and 1 label column in dataset\n",
    "X= dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 2 : Define Model\n",
    "# Here we are building models in keras as sequence of layers \n",
    "# Sequential()- create sequential object which allows us to add following defined models in forms of layers.\n",
    "model = Sequential()\n",
    "\n",
    "# We are creating fully connected feedback network here, that is why we have used Dense layer here.\n",
    "# In dense layer each neuron recieves input from all the neurons in the previous layer. It takes hidden layer neurons,  \n",
    "# input layer neurons and activation function as input.\n",
    "# we have used 'relu' as our activation function of hidden layers. reLu is Rectified Linear Unit. For last layer (output)\n",
    "# we have sigmoid as activation function (to activate this layer).\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 3: Compile Model \n",
    "# According to Keras documents : Compile configures the model for training. It defines the loss function, \n",
    "#the optimizer and the metrics that will be used to check your model (here it is accuracy), we have used \n",
    "# binary_crossentropy as out losses, for our labels are of two categgories (onset of diabetes as 1 or not as 0).\n",
    "# For optimizer we have used 'adam' (Advanced Adagrad + Momentum). It is gradient-based optimization which makes use of momentum.\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 443us/step - loss: 3.7079 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.9373 - acc: 0.5924\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.7478 - acc: 0.6432\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.7120 - acc: 0.6549\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6842 - acc: 0.6680\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6521 - acc: 0.6797\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6496 - acc: 0.6849\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6378 - acc: 0.6862\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6233 - acc: 0.6953\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6284 - acc: 0.6771\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6449 - acc: 0.6771\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6387 - acc: 0.6732\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6260 - acc: 0.6758\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6168 - acc: 0.7018\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6018 - acc: 0.6940\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5878 - acc: 0.7018\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5848 - acc: 0.6979\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6009 - acc: 0.6810\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5807 - acc: 0.7070\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5809 - acc: 0.7174\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5686 - acc: 0.7161\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5822 - acc: 0.6953\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5741 - acc: 0.7135\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5681 - acc: 0.7318\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5579 - acc: 0.7331\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5718 - acc: 0.7057\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5558 - acc: 0.7240\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5557 - acc: 0.7292\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5741 - acc: 0.7161\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5613 - acc: 0.7214\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5692 - acc: 0.7214\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5646 - acc: 0.7122\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5519 - acc: 0.7187\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5490 - acc: 0.7344\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5492 - acc: 0.7214\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5650 - acc: 0.7070\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5332 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5402 - acc: 0.7214\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5454 - acc: 0.7266\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5444 - acc: 0.7227\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5425 - acc: 0.7344\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5380 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5311 - acc: 0.7526\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5332 - acc: 0.7409\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5314 - acc: 0.7552\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5278 - acc: 0.7500\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5322 - acc: 0.7422\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5331 - acc: 0.7448\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5330 - acc: 0.7500\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5269 - acc: 0.7344\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5278 - acc: 0.7500\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5295 - acc: 0.7448\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5366 - acc: 0.7448\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5367 - acc: 0.7318\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.5221 - acc: 0.7487\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5288 - acc: 0.7435\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5308 - acc: 0.7344\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5219 - acc: 0.7526\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5116 - acc: 0.7591\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.5329 - acc: 0.7344\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5280 - acc: 0.7396\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5193 - acc: 0.7552\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5446 - acc: 0.7331\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5307 - acc: 0.7435\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5196 - acc: 0.7474\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 124us/step - loss: 0.5060 - acc: 0.7500\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.5150 - acc: 0.7383\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5130 - acc: 0.7552\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5145 - acc: 0.7565\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5369 - acc: 0.7253\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5177 - acc: 0.7357\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5158 - acc: 0.7474\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.5163 - acc: 0.7474\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5102 - acc: 0.7643\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.5091 - acc: 0.7604\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5111 - acc: 0.7500\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5164 - acc: 0.7591\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5113 - acc: 0.7500\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5139 - acc: 0.7409\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5107 - acc: 0.7565\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5058 - acc: 0.7682\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5048 - acc: 0.7552\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5002 - acc: 0.7578\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 102us/step - loss: 0.4979 - acc: 0.7604\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5055 - acc: 0.7500\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5067 - acc: 0.7565\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4995 - acc: 0.7526\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5029 - acc: 0.7656\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5058 - acc: 0.7682\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5092 - acc: 0.7565\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5023 - acc: 0.7565\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5057 - acc: 0.7422\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4982 - acc: 0.7643\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4994 - acc: 0.7591\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5036 - acc: 0.7526\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4915 - acc: 0.7669\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4976 - acc: 0.7721\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4892 - acc: 0.7630\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4910 - acc: 0.7734\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4842 - acc: 0.7799\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4902 - acc: 0.7747\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4993 - acc: 0.7591\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4999 - acc: 0.7565\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4917 - acc: 0.7839\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5320 - acc: 0.7435\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4932 - acc: 0.7721\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4905 - acc: 0.7721\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4999 - acc: 0.7734\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4860 - acc: 0.7630\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4893 - acc: 0.7695\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4843 - acc: 0.7760\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4941 - acc: 0.7669\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4975 - acc: 0.7604\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4920 - acc: 0.7604\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4916 - acc: 0.7773\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4969 - acc: 0.7682\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4915 - acc: 0.7591\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4926 - acc: 0.7760\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4832 - acc: 0.7682\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4943 - acc: 0.7799\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4939 - acc: 0.7734\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4873 - acc: 0.7747\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4851 - acc: 0.7682\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4852 - acc: 0.7812\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4880 - acc: 0.7812\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4829 - acc: 0.7708\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4914 - acc: 0.7643\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4721 - acc: 0.7786\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4835 - acc: 0.7695\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4742 - acc: 0.7865\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4836 - acc: 0.7669\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4846 - acc: 0.7747\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4838 - acc: 0.7682\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4852 - acc: 0.7734\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4784 - acc: 0.7773\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4747 - acc: 0.7773\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4686 - acc: 0.7760\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4820 - acc: 0.7734\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4679 - acc: 0.7917\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4826 - acc: 0.7865\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4742 - acc: 0.7891\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4843 - acc: 0.7721\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4766 - acc: 0.7669\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4772 - acc: 0.7695\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4919 - acc: 0.7656\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4934 - acc: 0.7682\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4856 - acc: 0.7734\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4724 - acc: 0.7734\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4767 - acc: 0.7695\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4762 - acc: 0.7721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb227b8b00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP - 4: Fit Model\n",
    "# Here are training out model for a fixed number of epochs(which are number of iteration on whole dataset) and batch_size(number of samples). \n",
    "model.fit(X,Y,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 71us/step\n",
      "\n",
      "acc:79.95%\n"
     ]
    }
   ],
   "source": [
    "# STEP - 5: Evaluate Model\n",
    "# In this Step we are evaluating our model again with same dataset that we have for training (fitting).\n",
    "# The metric that we are using to evalute is accuracy.\n",
    "scores = model.evaluate(X,Y)\n",
    "# In this print statement we have are printing metric name which i.e is Accuracy and then we are printing accuracy of model \n",
    "# in percentage format with only 2 places after decimal format.\n",
    "print(\"\\n%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Twitter sentiment identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "# To preprocess the data we need Tokenizer: here I have used nltk Tweet Tokenizer.\n",
    "# nltk is used for natural language processing and its Tweet tokenizer works specially on tweets data\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "# imported Sequential model to built layer-by-layer model. \n",
    "from keras.models import Sequential\n",
    "# imported Dense layer to build fully connected feedback network                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         to built layer-by-layer model. \n",
    "from keras.layers import Dense\n",
    "import numpy as np #importing numpy\n",
    "import pandas as pd #importing pandas\n",
    "np.random.seed(7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [is, so, sad, for, my, APL, friend, ...]\n",
       "1            [I, missed, the, New, Moon, trailer, ...]\n",
       "2                      [omg, its, already, 7:30, :, O]\n",
       "3    [.., Omgaga, ., Im, sooo, im, gunna, CRy, ., I...\n",
       "4    [i, think, mi, bf, is, cheating, on, me, !, !,...\n",
       "Name: SentimentText, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step-1 Load data and tokenize it .\n",
    "# load data by pandas library's read_csv function while changin the encoding of file to read floadt and string without any errors(which were present in original encodingof the file)\n",
    "dataset2 = pd.read_csv(\"train_validation-1.csv\", sep= \",\",encoding = \"ISO-8859-1\")\n",
    "\n",
    "# tokenizer divides a string into substrings by splitting on the specified character or string (such as white space)\n",
    "# Tweettokenizer comes with few normalization features, strip_handles removes all the words starting with #symbol, @symbol and take out all the URLs\n",
    "tokenizer = TweetTokenizer(strip_handles=True,reduce_len=True)\n",
    "# All the tweets are stored in text variable\n",
    "text = dataset2.iloc[:,2]\n",
    "# here we are tokenizing it the tokenizer object we created earlier\n",
    "tokens = text.apply(tokenizer.tokenize)\n",
    "# check the data\n",
    "tokens.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hmmm', '...', 'i', 'wonder', 'how', 'she', 'my', 'number', '@', '-', ')']\n",
      "['hmmm', '', 'i', 'wonder', 'how', 'she', 'my', 'number', '', '', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hmmm', 'i', 'wonder', 'how', 'she', 'my', 'number']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STEP-2 : Data Preprocessing \n",
    "\n",
    "# Import re to use regular expressions\n",
    "import re\n",
    "# convert to all the strings to lower case\n",
    "for a,b in tokens.iteritems(): \n",
    "    tokens[a] =[i.lower() for i in b]\n",
    "print(tokens[9]) \n",
    "\n",
    "# Substitute all the special characters and number's string with empty string,\n",
    "for a,b in tokens.iteritems(): \n",
    "    tokens[a] =[re.sub(r'[^a-zA-z0-9\\s]','',i) for i in b]\n",
    "print(tokens[9])   \n",
    "\n",
    "\n",
    "#Remove special characters like empty string and standalone alphanumeric characters\n",
    "for a,b in tokens.iteritems(): \n",
    "    tokens[a] =[i for i in b if (i.isalpha())]\n",
    "tokens[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hmmm', 'wonder', 'number']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Stop Words like is, am , the , how , i etc.\n",
    "# nltk.download('stopwords') # use it when running for the first tome\n",
    "\n",
    "# Import stopwords list from nltk corpus module\n",
    "from nltk.corpus import stopwords\n",
    "# created unordered set of stopwords of english language\n",
    "stop_words = set(stopwords.words('english'))\n",
    "allow_words = [\"not\", \"no\"]\n",
    "# match all the words in list of list with stop_words to remove them in final output\n",
    "for i,y in tokens.iteritems(): \n",
    "    tokens[i] = [x for x in y if x not in stop_words or x in allow_words ]\n",
    "        \n",
    "tokens[9]\n",
    "#reformed = [appos[word] if word in appos else word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 3: Data Normalization\n",
    "# Lemmatization\n",
    "# nltk.download('wordnet') # use it when running for the first tome\n",
    "\n",
    "# We lemmatize the stings to only root words because in sentiment analysis root word matter most and \"Beautifully\" and \"Beautiful\" is only one word for it. \n",
    "#Import WordNet lemmatizer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#create WordNetLemmatizer object\n",
    "lemmat = WordNetLemmatizer()\n",
    "for i,lst in tokens.iteritems(): \n",
    "     tokens[i] = [lemmat.lemmatize(word) for word in lst]\n",
    "#print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99989,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format from list of lists to lists of strings by joining all the tokenized strings to single strings sentence again.\n",
    "for i,lst in tokens.iteritems(): \n",
    "     tokens[i] = [' '.join(str(word) for word in lst) ]\n",
    "\n",
    "# convert the data type to dataframe\n",
    "df = pd.Series( (x[0] for x in tokens) )\n",
    "# Labels given in the original dataset file for Supervised learning \n",
    "yaxis= dataset2.iloc[:,1]\n",
    "yaxis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99989, 52323)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# STEP -4: Feature extraction (Vectorization)\n",
    "# CountVectorizer allows to build a vocabulary (i.e dictionary) of known words and to encode new documents using that vocabulary.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# create the CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "# tokenize here and fit the input dataframe on CountVectorizer model here.\n",
    "\n",
    "# In the vocabulary keys are the distinct words in the input dataframe and value \n",
    "# corresponding is the count of times each word appeared in that input dataframe\n",
    "vectorizer.fit(df)\n",
    "# \n",
    "#print(vectorizer.vocabulary_)\n",
    "# vectorized the input dataframe based on CountVectorizer model (encoding)  \n",
    "vector = vectorizer.transform(df)\n",
    "# convert scipy matrix to numpy array\n",
    "vec_array = vector.toarray()\n",
    "# Shape tell us the input of the first layer of model\n",
    "print(vector.shape)\n",
    "print(type(vec_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split whole dataset into 80% training and 20% testing data. Here we using sklearn to the slpit and \n",
    "# train_test_split function takes input x-axis (which is vectorized feature) , y-axis (labels given in the question), \n",
    "# test_size to know conversion ratio of test data and random_state variable to make random number predictable and get almost same answer at every run. \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(vec_array, yaxis , test_size=0.20, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Sequential model instance \n",
    "#model.add(Dense(12,activation='relu'))\n",
    "\n",
    "model = Sequential()\n",
    "# first layer of the model with input size of number of columns of vectorized array and 20 is the number of neurons with 'relu' as activation function \n",
    "model.add(Dense(12,input_dim=len(vec_array[0]),activation='relu'))\n",
    "# 2 more hidden layers of model with 'relu' as activation function activation \n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "# Output layer of model with only 1 column for output is only one of the two (1,0) and activation function is sigmoid\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model using binary_crossentropy for loss because it a binary classification and adam as optimizer with accuracy as metrics\n",
    "#optimizers = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "79991/79991 [==============================] - 125s 2ms/step - loss: 0.5374 - acc: 0.7347\n",
      "Epoch 2/4\n",
      "79991/79991 [==============================] - 123s 2ms/step - loss: 0.4159 - acc: 0.8086\n",
      "Epoch 3/4\n",
      "79991/79991 [==============================] - 109s 1ms/step - loss: 0.3328 - acc: 0.8534\n",
      "Epoch 4/4\n",
      "79991/79991 [==============================] - 157s 2ms/step - loss: 0.2638 - acc: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a27f2e240>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the data by 5 epochs because accuracy changed very little after 3 iterations(epochs) and taking in batch size = 10 \n",
    "model.fit(x_train,y_train,epochs=4,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79991/79991 [==============================] - 76s 951us/step\n",
      "\n",
      "acc:92.20%\n"
     ]
    }
   ],
   "source": [
    "# Summarize data by evaluating and printing it accuracy on training data \n",
    "# Here accuracy is very high because model is trained with training set and we are evaluating accuracy of training set only.\n",
    "scores = model.evaluate(x_train,y_train)\n",
    "print(\"\\n%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19998/19998 [==============================] - 14s 716us/step\n",
      "\n",
      "acc:74.36%\n"
     ]
    }
   ],
   "source": [
    "# Summarize data by evaluating and printing it accuracy on testing data \n",
    "\n",
    "scores = model.evaluate(x_test,y_test)\n",
    "print(\"\\n%s:%.2f%%\"%(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
